{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Fragment Reconstruction: CPU Inference & Evaluation\n\nThis notebook demonstrates how to load a trained fragment autoencoder checkpoint and perform CPU-based inference, clustering, metrics, and visualization. It is designed to run on a local machine without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU-centric settings\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # force CPU\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from study.fragmentation import FragmentBatchDataset, collate_fragment_batch\n",
    "from study.train_module import FragmentAE\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "print('Torch device:', 'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 1) Paths & Parameters\nUpdate these to point to your validation data directory and a trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_DIR = Path('data/imagenet64/dev_data')  # change to your validation images\n",
    "CKPT = Path('outputs/fragment_clustering_baseline/checkpoints/fragment-ae-epoch=00-val_loss=0.0836.ckpt')  # change to your best ckpt\n",
    "\n",
    "IMAGES_PER_SAMPLE = 10  # number of source images per sample (k for clustering)\n",
    "NUM_SAMPLES = 50        # how many samples to evaluate\n",
    "BATCH_SIZE = 1          # keep 1; each batch is a full unordered fragment set\n",
    "NUM_WORKERS = 0         # CPU-friendly, deterministic\n",
    "\n",
    "assert VAL_DIR.exists(), f'Validation directory not found: {VAL_DIR}'\n",
    "assert CKPT.exists(), f'Checkpoint not found: {CKPT}'\n",
    "print('Validation dir:', VAL_DIR)\n",
    "print('Checkpoint:', CKPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "## 2) Load Model (CPU)\nLoads the LightningModule on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model strictly on CPU\n",
    "try:\n",
    "    model = FragmentAE.load_from_checkpoint(str(CKPT), map_location='cpu')\n",
    "except Exception:\n",
    "    state = torch.load(CKPT, map_location='cpu')\n",
    "    model = FragmentAE()\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "\n",
    "model.eval(); model.cpu()\n",
    "print('Model loaded. Parameters:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## 3) DataLoader (CPU)\nBuild a small evaluation dataset on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FragmentBatchDataset(\n",
    "    images_dir=VAL_DIR,\n",
    "    images_per_sample=IMAGES_PER_SAMPLE,\n",
    "    steps_per_epoch=NUM_SAMPLES,\n",
    "    seed=123,\n",
    "    augment=False,\n",
    ")\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fragment_batch,\n",
    "    pin_memory=False,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "## 4) Helper Functions for Metrics & Visualization\nPurity, a simple grid helper, and one-batch evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def purity_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    clusters = defaultdict(list)\n",
    "    for t, p in zip(y_true, y_pred, strict=False):\n",
    "        clusters[int(p)].append(int(t))\n",
    "    total, correct = len(y_true), 0\n",
    "    for members in clusters.values():\n",
    "        counts = Counter(members)\n",
    "        correct += counts.most_common(1)[0][1]\n",
    "    return correct / float(total) if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def make_grid(imgs: np.ndarray, cols: int = 10) -> np.ndarray:\n",
    "    N = imgs.shape[0]\n",
    "    rows = int(np.ceil(N / cols))\n",
    "    H, W = 16, 16\n",
    "    grid = np.ones((rows * H, cols * W, 3), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        r, c = divmod(i, cols)\n",
    "        grid[r*H:(r+1)*H, c*W:(c+1)*W] = imgs[i]\n",
    "    return grid\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_batch(model: FragmentAE, batch, k: int):\n",
    "    _, z = model(batch.fragments.cpu())\n",
    "    z_np = z.detach().cpu().numpy()\n",
    "    y_true = batch.source_ids.detach().cpu().numpy()\n",
    "\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=0)\n",
    "    y_pred = km.fit_predict(z_np)\n",
    "\n",
    "    ari = adjusted_rand_score(y_true, y_pred)\n",
    "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "    pur = purity_score(y_true, y_pred)\n",
    "    return ari, nmi, pur, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "## 5) Evaluate on CPU\nCompute ARI, NMI, and Purity over a number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_list, nmi_list, pur_list = [], [], []\n",
    "for i, batch in enumerate(loader):\n",
    "    ari, nmi, pur, _ = eval_one_batch(model, batch, k=IMAGES_PER_SAMPLE)\n",
    "    ari_list.append(ari); nmi_list.append(nmi); pur_list.append(pur)\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f'Processed {i+1}/{len(loader)}')\n",
    "\n",
    "print({\n",
    "    'samples': len(ari_list),\n",
    "    'ARI_mean': float(np.mean(ari_list)) if ari_list else 0.0,\n",
    "    'NMI_mean': float(np.mean(nmi_list)) if nmi_list else 0.0,\n",
    "    'Purity_mean': float(np.mean(pur_list)) if pur_list else 0.0,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "source": [
    "## 6) Visualize a Single Sample\nShow predicted clusters vs. true groups for one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))\n",
    "_, _, _, y_pred = eval_one_batch(model, batch, k=IMAGES_PER_SAMPLE)\n",
    "frags = batch.fragments.detach().cpu().numpy().transpose(0,2,3,1)  # [N,16,16,3]\n",
    "y_true = batch.source_ids.detach().cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, IMAGES_PER_SAMPLE, figsize=(2*IMAGES_PER_SAMPLE, 4))\n",
    "axes = np.atleast_2d(axes)\n",
    "for cid in range(IMAGES_PER_SAMPLE):\n",
    "    idxs = np.where(y_pred == cid)[0][:20]\n",
    "    grid = make_grid(frags[idxs], cols=10) if len(idxs) else np.ones((16,16,3))\n",
    "    axes[0, cid].imshow(grid); axes[0, cid].set_title(f'Pred {cid}'); axes[0, cid].axis('off')\n",
    "\n",
    "    t_idxs = np.where(y_true == cid)[0][:20]\n",
    "    t_grid = make_grid(frags[t_idxs], cols=10) if len(t_idxs) else np.ones((16,16,3))\n",
    "    axes[1, cid].imshow(t_grid); axes[1, cid].set_title(f'True {cid}'); axes[1, cid].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
