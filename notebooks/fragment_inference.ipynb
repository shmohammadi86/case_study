{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fragment Reconstruction: CPU Inference & Evaluation\n\nThis notebook demonstrates how to load a trained fragment autoencoder checkpoint and perform CPU-based inference, clustering, metrics, and visualization. It is designed to run on a local machine without GPUs."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CPU-centric settings\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = ''  # force CPU\n\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n\nfrom study.fragmentation import FragmentBatchDataset, collate_fragment_batch\nfrom study.train_module import FragmentAE\n\npl.seed_everything(42, workers=True)\nprint('Torch device:', 'cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["## 1) Paths & Parameters\nUpdate these to point to your validation data directory and a trained checkpoint."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["VAL_DIR = Path('data/imagenet64/dev_data')  # change to your validation images\nCKPT = Path('outputs/fragment_clustering_baseline/checkpoints/fragment-ae-epoch=00-val_loss=0.0836.ckpt')  # change to your best ckpt\n\nIMAGES_PER_SAMPLE = 10  # number of source images per sample (k for clustering)\nNUM_SAMPLES = 50        # how many samples to evaluate\nBATCH_SIZE = 1          # keep 1; each batch is a full unordered fragment set\nNUM_WORKERS = 0         # CPU-friendly, deterministic\n\nassert VAL_DIR.exists(), f'Validation directory not found: {VAL_DIR}'\nassert CKPT.exists(), f'Checkpoint not found: {CKPT}'\nprint('Validation dir:', VAL_DIR)\nprint('Checkpoint:', CKPT)"]},{"cell_type":"markdown","metadata":{},"source":["## 2) Load Model (CPU)\nLoads the LightningModule on CPU."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load model strictly on CPU\ntry:\n    model = FragmentAE.load_from_checkpoint(str(CKPT), map_location='cpu')\nexcept Exception:\n    state = torch.load(CKPT, map_location='cpu')\n    model = FragmentAE()\n    model.load_state_dict(state['state_dict'])\n\nmodel.eval(); model.cpu();\nprint('Model loaded. Parameters:', sum(p.numel() for p in model.parameters()))"]},{"cell_type":"markdown","metadata":{},"source":["## 3) DataLoader (CPU)\nBuild a small evaluation dataset on CPU."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ds = FragmentBatchDataset(\n    images_dir=VAL_DIR,\n    images_per_sample=IMAGES_PER_SAMPLE,\n    steps_per_epoch=NUM_SAMPLES,\n    seed=123,\n    augment=False,\n)\nloader = DataLoader(\n    ds,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    collate_fn=collate_fragment_batch,\n    pin_memory=False,\n)\nlen(ds)" ]},{"cell_type":"markdown","metadata":{},"source":["## 4) Helper Functions for Metrics & Visualization\nPurity, a simple grid helper, and one-batch evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter, defaultdict\n\n\ndef purity_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    clusters = defaultdict(list)\n    for t, p in zip(y_true, y_pred):\n        clusters[int(p)].append(int(t))\n    total, correct = len(y_true), 0\n    for members in clusters.values():\n        counts = Counter(members)\n        correct += counts.most_common(1)[0][1]\n    return correct / float(total) if total > 0 else 0.0\n\n\ndef make_grid(imgs: np.ndarray, cols: int = 10) -> np.ndarray:\n    N = imgs.shape[0]\n    rows = int(np.ceil(N / cols))\n    H, W = 16, 16\n    grid = np.ones((rows * H, cols * W, 3), dtype=np.float32)\n    for i in range(N):\n        r, c = divmod(i, cols)\n        grid[r*H:(r+1)*H, c*W:(c+1)*W] = imgs[i]\n    return grid\n\n\n@torch.no_grad()\ndef eval_one_batch(model: FragmentAE, batch, k: int):\n    _, z = model(batch.fragments.cpu())\n    z_np = z.detach().cpu().numpy()\n    y_true = batch.source_ids.detach().cpu().numpy()\n\n    km = KMeans(n_clusters=k, n_init=10, random_state=0)\n    y_pred = km.fit_predict(z_np)\n\n    ari = adjusted_rand_score(y_true, y_pred)\n    nmi = normalized_mutual_info_score(y_true, y_pred)\n    pur = purity_score(y_true, y_pred)\n    return ari, nmi, pur, y_pred\n"]},{"cell_type":"markdown","metadata":{},"source":["## 5) Evaluate on CPU\nCompute ARI, NMI, and Purity over a number of samples."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ari_list, nmi_list, pur_list = [], [], []\nfor i, batch in enumerate(loader):\n    ari, nmi, pur, _ = eval_one_batch(model, batch, k=IMAGES_PER_SAMPLE)\n    ari_list.append(ari); nmi_list.append(nmi); pur_list.append(pur)\n    if (i+1) % 10 == 0:\n        print(f'Processed {i+1}/{len(loader)}')\n\nprint({\n    'samples': len(ari_list),\n    'ARI_mean': float(np.mean(ari_list)) if ari_list else 0.0,\n    'NMI_mean': float(np.mean(nmi_list)) if nmi_list else 0.0,\n    'Purity_mean': float(np.mean(pur_list)) if pur_list else 0.0,\n})"]},{"cell_type":"markdown","metadata":{},"source":["## 6) Visualize a Single Sample\nShow predicted clusters vs. true groups for one sample."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch = next(iter(loader))\n_, _, _, y_pred = eval_one_batch(model, batch, k=IMAGES_PER_SAMPLE)\nfrags = batch.fragments.detach().cpu().numpy().transpose(0,2,3,1)  # [N,16,16,3]\ny_true = batch.source_ids.detach().cpu().numpy()\n\nfig, axes = plt.subplots(2, IMAGES_PER_SAMPLE, figsize=(2*IMAGES_PER_SAMPLE, 4))\naxes = np.atleast_2d(axes)\nfor cid in range(IMAGES_PER_SAMPLE):\n    idxs = np.where(y_pred == cid)[0][:20]\n    grid = make_grid(frags[idxs], cols=10) if len(idxs) else np.ones((16,16,3))\n    axes[0, cid].imshow(grid); axes[0, cid].set_title(f'Pred {cid}'); axes[0, cid].axis('off')\n\n    t_idxs = np.where(y_true == cid)[0][:20]\n    t_grid = make_grid(frags[t_idxs], cols=10) if len(t_idxs) else np.ones((16,16,3))\n    axes[1, cid].imshow(t_grid); axes[1, cid].set_title(f'True {cid}'); axes[1, cid].axis('off')\n\nplt.tight_layout()\nplt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12"}},"nbformat":4,"nbformat_minor":5}
